<!DOCTYPE html>
<!-- saved from url=(0066)http://www.stat.ucla.edu/~tianmin.shu/AerialVideo/AerialVideo.html -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Shared Attention</title>

    <!-- Bootstrap Core CSS -->
    <link href="./SharedAttention_CVPR18/shared_attention_files/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="./SharedAttention_CVPR18/shared_attention_files/scrolling-nav.css" rel="stylesheet">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

<link href="chrome-extension://lnkdbjbjpnpjeciipoaflmpcddinpjjp/mytube.css" rel="stylesheet" type="text/css"><script src="chrome-extension://lnkdbjbjpnpjeciipoaflmpcddinpjjp/mutationObserver.js"></script><script src="chrome-extension://lnkdbjbjpnpjeciipoaflmpcddinpjjp/mytube.js"></script></head>

<!-- The #page-top ID is part of the scrolling feature - the data-spy and data-target are part of the built-in Bootstrap scrollspy function -->

<body id="page-top" data-spy="scroll" data-target=".navbar-fixed-top">

    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-fixed-top" role="navigation">
        <div class="container">
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>-
                </button>
                <!--<a class="navbar-brand page-scroll" href="#page-top">Start Bootstrap</a>-->
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse navbar-ex1-collapse">
                <ul class="nav navbar-nav">
                    <!-- Hidden li included to remove active class from about link when scrolled up past about section -->
                    <li class="active">
                        <a class="page-scroll" href="http://www.stat.ucla.edu/~lifengfan/shared_attention.html#abstract">Introduction</a>
                    </li>
                    <li class="">
                        <a class="page-scroll" href="http://www.stat.ucla.edu/~lifengfan/shared_attention.html#paper">Paper and Demo</a>
                    </li>
			<li class="">
                        <a class="page-scroll" href="http://www.stat.ucla.edu/~lifengfan/shared_attention.html#data">Dataset</a>
                    </li>
                    <li class="">
                        <a class="page-scroll" href="http://www.stat.ucla.edu/~lifengfan/shared_attention.html#contact">Contact</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

    <!-- Intro Section -->
    <section id="abstract" class="intro-section">
	<div class="container">
            <div class="row">
                <div class="col-lg-12">
                    <h1>Inferring Shared Attention in Social Scene Videos</h1>
                    <h3><a href="http://www.stat.ucla.edu/~lifengfan">Lifeng Fan</a><sup>&#9913 1</sup>, <a href="">Yixin Chen</a><sup>&#9913 1</sup>, <a href="http://www.stat.ucla.edu/~pwei/">Ping Wei</a><sup>2,1</sup>, <a href="https://sites.google.com/site/wenguanwangwwg/">Wenguan Wang</a><sup>3,1</sup> and <a href="http://www.stat.ucla.edu/~sczhu">Song-Chun Zhu</a><sup>1</sup> </h3>
			
	            <p><a href="http://vcla.stat.ucla.edu/index.html">Center for Vision, Cognition, Learning, and Autonomy, UCLA</a><sup>1</sup></p>
			
		    <p><a href="http://en.xjtu.edu.cn/">Xi’an Jiaotong University</a><sup>2</sup></p>

		    <p><a href="http://english.bit.edu.cn/">Beijing Institute of Technology</a><sup>3</sup></p>
                    <p>(&#9913 indicates equal contribution.)</p>

<img src="./SharedAttention_CVPR18/shared_attention_files/dataset.jpg" alt="VideoCoAtt DataSet" style="width:800px;height:266px">

		<h2>Abstract</h2>

                    <p align="justify"> This paper addresses a new problem of inferring shared attention in third-person social scene videos. Shared attention is a phenomenon that two or more individuals simultaneously look at a common target in social scenes. Perceiving and identifying shared attention in videos plays crucial roles in social activities and social scene understanding. We propose a spatial-temporal neural network to detect shared attention intervals in videos and predict shared attention locations in frames. In each video frame, human gaze directions and potential target boxes are two key features for spatially detecting shared attention in the social scene. In temporal domain, a convolutional Long Short-Term Memory network utilizes the temporal continuity and transition constraints to optimize the predicted shared attention heatmap.  We collect a new dataset VideoCoAtt from public TV show videos, containing 380 complex video sequences with more than 492,000 frames that include diverse social scenes for shared attention study. Experiments on this dataset show that our model can effectively infer shared attention in videos. We also empirically verify the effectiveness of different components in our model. </p>


                </div>
            </div>
        </div>
    </section>

    <!-- Services Section -->
    <section id="paper" class="paper-section">
        <div class="container">
            <div class="row">
                <div class="col-lg-12">
                    <h2>Paper and Demo</h2>
<h3 align="justify"> Paper</h3> 
		    <p align="justify">Lifeng Fan<sup>&#9913</sup>, Yixin Chen<sup>&#9913</sup>, Ping Wei, Wenguan Wang and Song-Chun Zhu. Inferring Shared Attention in Social Scene Videos. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018. [<a href="http://www.stat.ucla.edu/~lifengfan/SharedAttention_CVPR18/shared_attention_camera_ready.pdf">pdf</a>] </p> 
                    <div>
		      <pre class="citation" align="left">@inproceedings{FanCVPR2018,
  title     = {Inferring Shared Attention in Social Scene Videos},
  author    = {Lifeng Fan and Yixin Chen and Ping Wei and Wenguan Wang and Song-Chun Zhu},
  year      = {2018},
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}
}</pre>
                    </div>
<div style="text-align: center"> 
<h3 align="justify"> Demo</h3> 
		    <!--<iframe width="560" height="315" src="./SharedAttention_CVPR18/shared_attention_files/nKzwfLa2lvc.html" frameborder="0" allowfullscreen="" mytubeid="mytube1"></iframe> -->
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/4uA5buFgi38?ecver=1" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

</div>              
		</div>
            </div>
        </div>
    </section>

    <!-- Services Section -->
    <section id="data" class="data-section">
        <div class="container">
            <div class="row">
                <div class="col-lg-12">
                    <h2>VideoCoAtt Dataset</h2>

<!--
<h3 align="justify">Introduction</h3>
<p align="justify">
At UCLA, we assembled a new low-cost hex-rotor with a GoPro
camera, which is able to eliminate the
high frequency vibration of the camera and hold in air autonomously through a GPS and a barometer. It can also
fly 20 ∼ 90m above the ground and stays 5 minutes in
air. We use this hex-rotor to take a set of videos with some
plots at a park where the terrain is interesting: hiking routes,
parking lots, camping sites, picnic areas with shelters, restrooms, tables, trash bins and BBQ ovens. By detecting/tracking humans and objects in the videos, we can recognize events such as BBQ, queuing, exchanging objects,
loading/unloading, etc.</p>
<p align="justify">
We have collected some events with scripts involving
the interactions between humans and objects at two different sites. The original
videos are pre-processed, including camera calibration and
frame registration. After pre-processing, there are totally
27 videos in the dataset, the length of which ranges from 2
minutes to 5 minutes. We annotate the hierarchical semantic information of objects, roles, events and groups in the
videos.
</p>

<div class="row"> 
	<div class="col-lg-12" align="center">
		<img src="./Aerial Video_files/rotor.png" alt="rotor" style="width:300px;height:169px">
		<p>Image of our hex-rotor in the air with a GoPro camera.</p>
	</div>
</div>
<div class="row">
<div class="col-lg-1"></div>
<div class="col-lg-5" align="center">
		<img src="./Aerial Video_files/screenshot.png" alt="frame" style="width:433px;height:244px">
		<p>A frame of the original aerial videos from site A.</p>
	</div>
<div class="col-lg-5" align="center">
		<img src="./Aerial Video_files/screenshot2.png" alt="frame2" style="width:433px;height:244px">
		<p>A frame of the original aerial videos from site B.</p>
	</div>
<div class="col-lg-1"></div>
 </div>
</div>

<h3 align="justify">Summary of dataset</h3>
<p align="justify">
The annotation in our dataset includes individuals, objects, groups, events. human roles and goals (destinations). There are 12 events, 18 human roles, 12 object categories. (In our CVPR 2015 paper, we didn't investigate the "Inspection Hide" group events and inidvidual goals.)
</p>
<div class="row"> 
	<div class="col-lg-12" align="center">
		<img src="./Aerial Video_files/summary.png" alt="summary" style="width:608px;height:241px">
	</div>
</div> -->

<!-- <h3 align="justify"> Download</h3> -->
	            <!--<p  align = 'justify'>You can download the dataset including stablized videos and detailed annotation <strong> <a href=>here</a>. </strong></p>
<h3 align = 'justify'> Citation</h3>-->
		    <p align="justify">The dataset is available for free only for research purposes. You download the dataset from  <a href="https://drive.google.com/a/g.ucla.edu/file/d/1Fp79WQjgOxOXlflZGCh2jlPat8cJenzJ/view?usp=sharing">here</a>.

</p> 
<p align="justify">We greatly welcome emails about questions or suggestions. Please email to lfan [at] ucla.edu.</p>
		    <p align="justify">Please cite this paper if you use the dataset:</p>
			<p align="justify"><strong>Lifeng Fan<sup>&#9913</sup>, Yixin Chen<sup>&#9913</sup>, Ping Wei, Wenguan Wang and Song-Chun Zhu. Inferring Shared Attention in Social Scene Videos. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018.</strong></p>



                </div>
            </div>
        
    </section>

    <!-- Contact Section -->
    <section id="contact" class="contact-section">
        <div class="container">
            <div class="row">
                <div class="col-lg-12">
                    <h1>Contact</h1>
		    Any question? Please contact Lifeng Fan (lfan [at] ucla.edu)
                </div>
            </div>
        </div>
    </section>

    <!-- jQuery -->
    <script src="./SharedAttention_CVPR18/shared_attention_files/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="./SharedAttention_CVPR18/shared_attention_files/bootstrap.min.js"></script>

    <!-- Scrolling Nav JavaScript -->
    <script src="./SharedAttention_CVPR18/shared_attention_files/jquery.easing.min.js"></script>
    <script src="./SharedAttention_CVPR18/shared_attention_files/scrolling-nav.js"></script>




<mytubeelement id="myTubeRelayElementToPage" event="preferencesUpdated" data="{&quot;bundle&quot;:{&quot;label_delimitor&quot;:&quot;:&quot;,&quot;percentage&quot;:&quot;%&quot;,&quot;smart_buffer&quot;:&quot;Smart Buffer&quot;,&quot;start_playing_when_buffered&quot;:&quot;Start playing when buffered&quot;,&quot;sound&quot;:&quot;Sound&quot;,&quot;desktop_notification&quot;:&quot;Desktop Notification&quot;,&quot;continuation_on_next_line&quot;:&quot;-&quot;,&quot;loop&quot;:&quot;Loop&quot;,&quot;only_notify&quot;:&quot;Only Notify&quot;,&quot;estimated_time&quot;:&quot;Estimated Time&quot;,&quot;global_preferences&quot;:&quot;Global Preferences&quot;,&quot;no_notification_supported_on_your_browser&quot;:&quot;No notification style supported on your browser version&quot;,&quot;video_buffered&quot;:&quot;Video Buffered&quot;,&quot;buffered&quot;:&quot;Buffered&quot;,&quot;hyphen&quot;:&quot;-&quot;,&quot;buffered_message&quot;:&quot;The video has been buffered as requested and is ready to play.&quot;,&quot;not_supported&quot;:&quot;Not Supported&quot;,&quot;on&quot;:&quot;On&quot;,&quot;off&quot;:&quot;Off&quot;,&quot;click_to_enable_for_this_site&quot;:&quot;Click to enable for this site&quot;,&quot;desktop_notification_denied&quot;:&quot;You have denied permission for desktop notification for this site&quot;,&quot;notification_status_delimitor&quot;:&quot;;&quot;,&quot;error&quot;:&quot;Error&quot;,&quot;adblock_interferance_message&quot;:&quot;Adblock (or similar extension) is known to interfere with SmartVideo. Please add this url to adblock whitelist.&quot;,&quot;calculating&quot;:&quot;Calculating&quot;,&quot;waiting&quot;:&quot;Waiting&quot;,&quot;will_start_buffering_when_initialized&quot;:&quot;Will start buffering when initialized&quot;,&quot;will_start_playing_when_initialized&quot;:&quot;Will start playing when initialized&quot;,&quot;completed&quot;:&quot;Completed&quot;,&quot;buffering_stalled&quot;:&quot;Buffering is stalled. Will stop.&quot;,&quot;stopped&quot;:&quot;Stopped&quot;,&quot;hr&quot;:&quot;Hr&quot;,&quot;min&quot;:&quot;Min&quot;,&quot;sec&quot;:&quot;Sec&quot;,&quot;any_moment&quot;:&quot;Any Moment&quot;,&quot;popup_donate_to&quot;:&quot;Donate to&quot;,&quot;extension_id&quot;:&quot;lnkdbjbjpnpjeciipoaflmpcddinpjjp&quot;},&quot;prefs&quot;:{&quot;desktopNotification&quot;:true,&quot;soundNotification&quot;:true,&quot;logLevel&quot;:0,&quot;enable&quot;:true,&quot;loop&quot;:false,&quot;hidePopup&quot;:false,&quot;autoPlay&quot;:false,&quot;autoBuffer&quot;:false,&quot;autoPlayOnBuffer&quot;:false,&quot;autoPlayOnBufferPercentage&quot;:42,&quot;autoPlayOnSmartBuffer&quot;:true,&quot;quality&quot;:&quot;default&quot;,&quot;fshd&quot;:false,&quot;onlyNotification&quot;:false,&quot;enableFullScreen&quot;:true,&quot;saveBandwidth&quot;:false,&quot;hideAnnotations&quot;:false,&quot;turnOffPagedBuffering&quot;:false}}"></mytubeelement><mytubeelement id="myTubeRelayElementToTab" event="relayPrefs" data="{&quot;loadBundle&quot;:true}"></mytubeelement></body></html>
